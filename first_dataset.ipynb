{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiro dataset\n",
    "\n",
    "Dataset escolhido: [https://archive.ics.uci.edu/dataset/602/dry+bean+dataset](https://archive.ics.uci.edu/dataset/602/dry+bean+dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_data = 'data/Dry_Bean_Dataset.xlsx'\n",
    "\n",
    "# Carregar base de dados\n",
    "# DataFrame\n",
    "HEADER_ROW = 0\n",
    "dataset = pd.read_excel(path_to_data, sheet_name=\"Dry_Beans_Dataset\",header=HEADER_ROW)\n",
    "\n",
    "# DEBUG - Verificar se a base de dados foi carregada corretamente\n",
    "# dataset.head(20)\n",
    "# dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando as labels em valores numéricos\n",
    "dataset['Class'] = dataset['Class'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os dados\n",
    "Seperação dos dados em features (X) e target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_COLUMNS = len(dataset.columns)\n",
    "\n",
    "y = dataset.iloc[:,-1] # extrai o target (última coluna)\n",
    "X = dataset.iloc[:,0:NUM_OF_COLUMNS-1] # extrai as features (todas as colunas menos a última)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando os dados\n",
    "Deixando os valores de todas as colunas entre 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_values = X.values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x_values)\n",
    "X = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando os folds\n",
    "Serão 10 folds para o k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Transforma para array NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Define o número de folds\n",
    "N_FOLDS = 10\n",
    "kf = StratifiedKFold(n_splits=N_FOLDS)\n",
    "\n",
    "# features e target de treino\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# features e target de teste\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "  X_train.append(X[train_index])\n",
    "  X_test.append(X[test_index])\n",
    "\n",
    "  y_train.append(y[train_index])\n",
    "  y_test.append(y[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo os scores dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "from sklearn import metrics\n",
    "\n",
    "def predict_and_get_accuracy(model, X_test: List[Any], y_test: List[Any]) -> float:\n",
    "  y_pred = model.predict(X_test)\n",
    "  accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média da árvore de decisão com ENTROPY: 79.58%\n",
      "Acurácia média da árvore de decisão com GINI: 74.13%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "gini_tree_results = []\n",
    "entropy_tree_results = []\n",
    "\n",
    "TREE_RANDOM_STATE = 42\n",
    "TREE_MAX_DEPTH = 5\n",
    "\n",
    "# Treinamento e avaliação do modelo com critério entropy\n",
    "for i in range(N_FOLDS):\n",
    "  entropy_tree_model = DecisionTreeClassifier(criterion=\"entropy\", random_state=TREE_RANDOM_STATE,\n",
    "    max_depth=TREE_MAX_DEPTH)\n",
    "  entropy_tree_model = entropy_tree_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  entropy_tree_results.append(predict_and_get_accuracy(entropy_tree_model, X_test[i], y_test[i]))\n",
    "\n",
    "print(f\"Acurácia média da árvore de decisão com ENTROPY: { \\\n",
    "  np.mean(entropy_tree_results)*100:.2f}%\")\n",
    "\n",
    "# Treinamento e avaliação do modelo com critério gini\n",
    "for i in range(N_FOLDS):\n",
    "  gini_tree_model = DecisionTreeClassifier(criterion=\"gini\", random_state=TREE_RANDOM_STATE,\n",
    "    max_depth=TREE_MAX_DEPTH)\n",
    "  gini_tree_model = gini_tree_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  gini_tree_results.append(predict_and_get_accuracy(gini_tree_model, X_test[i], y_test[i]))\n",
    "\n",
    "print(f\"Acurácia média da árvore de decisão com GINI: { \\\n",
    "  np.mean(gini_tree_results)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média do KNN com 5 vizinhos: 87.61%\n",
      "Acurácia média do KNN com 10 vizinhos: 88.36%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "five_neighbors_results = []\n",
    "ten_neighbors_results = []\n",
    "\n",
    "# Treinamento e avaliação do modelo com 5 vizinhos\n",
    "for i in range(N_FOLDS):\n",
    "  five_neighbors_model = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
    "  five_neighbors_model = five_neighbors_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  five_neighbors_results.append(predict_and_get_accuracy(five_neighbors_model, X_test[i], y_test[i]))\n",
    "\n",
    "print(f\"Acurácia média do KNN com 5 vizinhos: { \\\n",
    "  np.mean(five_neighbors_results)*100:.2f}%\")\n",
    "\n",
    "# Treinamento e avaliação do modelo com 10 vizinhos\n",
    "for i in range(N_FOLDS):\n",
    "  ten_neighbors_model = KNeighborsClassifier(n_neighbors=10, metric=\"euclidean\")\n",
    "  ten_neighbors_model = ten_neighbors_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  ten_neighbors_results.append(predict_and_get_accuracy(ten_neighbors_model, X_test[i], y_test[i]))\n",
    "\n",
    "print(f\"Acurácia média do KNN com 10 vizinhos: { \\\n",
    "  np.mean(ten_neighbors_results)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média da MLP com arquitetura (10, 2) e função de ativação RELU: 87.71%\n",
      "Acurácia média da MLP com arquitetura (50,) e função de ativação RELU: 88.59%\n",
      "Acurácia média da MLP com arquitetura (10, 2) e função de ativação TANH: 88.60%\n",
      "Acurácia média da MLP com arquitetura (50,) e função de ativação TANH: 88.92%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "FIRST_ARCHITECTURE = (10, 2,)\n",
    "SECOND_ARCHITECTURE = (50, )\n",
    "\n",
    "mlp_first_architecture_results = {\n",
    "    \"tanh\": [],\n",
    "    \"relu\": [],\n",
    "}\n",
    "\n",
    "mlp_second_architecture_results = {\n",
    "    \"tanh\": [],\n",
    "    \"relu\": [],\n",
    "}\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "  \n",
    "  # Treinamento e avaliação do modelo com função de ativação RELU (FIRST_ACHITECTURE)\n",
    "  first_relu_mlp_model = MLPClassifier(hidden_layer_sizes=FIRST_ARCHITECTURE,\n",
    "    random_state=42, max_iter=1000)\n",
    "  first_relu_mlp_model = first_relu_mlp_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  mlp_first_architecture_results[\"relu\"].append(\n",
    "    predict_and_get_accuracy(first_relu_mlp_model, X_test[i], y_test[i]))\n",
    "\n",
    "  # Treinamento e avaliação do modelo com função de ativação RELU (SECOND_ARCHITECTURE)  \n",
    "  second_relu_mlp_model = MLPClassifier(hidden_layer_sizes=SECOND_ARCHITECTURE,\n",
    "    random_state=42, max_iter=1000)\n",
    "  second_relu_mlp_model = second_relu_mlp_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  mlp_second_architecture_results[\"relu\"].append(\n",
    "    predict_and_get_accuracy(second_relu_mlp_model, X_test[i], y_test[i]))\n",
    "  \n",
    "  # Treinamento e avaliação do modelo com função de ativação TANH (FIRST_ARCHITECTURE)\n",
    "  first_tanh_mlp_model = MLPClassifier(hidden_layer_sizes=FIRST_ARCHITECTURE,\n",
    "    random_state=42, max_iter=1000, activation=\"tanh\")\n",
    "  first_tanh_mlp_model = first_tanh_mlp_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  mlp_first_architecture_results[\"tanh\"].append(\n",
    "    predict_and_get_accuracy(first_tanh_mlp_model, X_test[i], y_test[i]))\n",
    "  \n",
    "  # Treinamento e avaliação do modelo com função de ativação TANH (SECOND_ARCHITECTURE)\n",
    "  second_tanh_mlp_model = MLPClassifier(hidden_layer_sizes=SECOND_ARCHITECTURE,\n",
    "    random_state=42, max_iter=1000, activation=\"tanh\")\n",
    "  second_tanh_mlp_model = second_tanh_mlp_model.fit(X_train[i], y_train[i])\n",
    "\n",
    "  mlp_second_architecture_results[\"tanh\"].append(\n",
    "    predict_and_get_accuracy(second_tanh_mlp_model, X_test[i], y_test[i]))\n",
    "\n",
    "# Exibindo as acurácias dos modelos\n",
    "print(f\"Acurácia média da MLP com arquitetura {FIRST_ARCHITECTURE} e função de ativação RELU: { \\\n",
    "  np.mean(mlp_first_architecture_results[\"relu\"])*100:.2f}%\")\n",
    "\n",
    "print(f\"Acurácia média da MLP com arquitetura {SECOND_ARCHITECTURE} e função de ativação RELU: { \\\n",
    "  np.mean(mlp_second_architecture_results[\"relu\"])*100:.2f}%\")\n",
    "\n",
    "print(f\"Acurácia média da MLP com arquitetura {FIRST_ARCHITECTURE} e função de ativação TANH: { \\\n",
    "  np.mean(mlp_first_architecture_results[\"tanh\"])*100:.2f}%\")\n",
    "\n",
    "print(f\"Acurácia média da MLP com arquitetura {SECOND_ARCHITECTURE} e função de ativação TANH: { \\\n",
    "  np.mean(mlp_second_architecture_results[\"tanh\"])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções utilizadas para o mapeamento das labels geradas para os clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "def create_cluster_label_mapping_lists(n_clusters: int) -> List[List[int]]:\n",
    "  \"\"\"\n",
    "  Cria a lista com as listas aninhadas que mapeiam os targets (classes) para cada cluster.\n",
    "\n",
    "  Parametros\n",
    "  ----------\n",
    "  n_clusters : int -\n",
    "    Número de clusters distintos.\n",
    "  \n",
    "  Retorna\n",
    "  ----------\n",
    "  List[List[int]]\n",
    "    Uma lista onde cada posição corresponde a um cluster (índice 0 == cluster 0) e, nessa posição,\n",
    "    há uma lista que armazenará os targets (valores classificados) para o cluster em questão.\n",
    "  \"\"\"\n",
    "  return [[] for i in range(n_clusters)]\n",
    "\n",
    "def map_clusters_to_labels(model: KMeans, n_clusters: int, y_train: np.ndarray):\n",
    "  \"\"\"\n",
    "  Obtém as labels dos clusters do KMeans e mapeia os targets (classes) correspondentes a cada\n",
    "  cluster.\n",
    "\n",
    "  Parametros\n",
    "  ----------\n",
    "  model : KMeans -\n",
    "    Modelo KMeans que é utilizado para obter as labels dos clusters.\n",
    "  n_clusters : int -\n",
    "    Número de clusters distintos.\n",
    "  y_train : np.ndarray\n",
    "    Array NumPy com os targets do conjunto de treino.\n",
    "  \n",
    "  Retorna\n",
    "  ----------\n",
    "  List[List[int]]\n",
    "    Uma lista onde cada posição corresponde a um cluster (índice 0 == cluster 0) e, nessa posição,\n",
    "    há uma lista contendo os targets (valores classificados) para o cluster em questão.\n",
    "  \"\"\"\n",
    "  labels = model.labels_\n",
    "\n",
    "  y_train_as_list = y_train.tolist()\n",
    "\n",
    "  mapped_cluster_labels = create_cluster_label_mapping_lists(n_clusters)\n",
    "\n",
    "  for i in range(len(y_train)):  # para cada y do conjunto de treino\n",
    "    for c in range(n_clusters):  # para cada cluster\n",
    "      if labels[i] == c:\n",
    "\n",
    "      # se a label atual for igual ao número do cluster atual,\n",
    "      # adicione o valor de y (target) correspondente ao array de posição c\n",
    "      # (colocar o y de treino no seu cluster equivalente)\n",
    "      # labels[i] foi classificado como y_train_as_list[i]\n",
    "\n",
    "        mapped_cluster_labels[c].append(y_train_as_list[i])\n",
    "  \n",
    "  return mapped_cluster_labels\n",
    "\n",
    "def create_label_to_class_mapping(mapped_cluster_labels: List[List[int]], n_clusters: int\n",
    "  ) -> dict[int, int]:\n",
    "  \"\"\"\n",
    "  Obtém a classe associada (target) a cada cluster.\n",
    "  \n",
    "  Parametros\n",
    "  ----------\n",
    "  mapped_cluster_labels : List[List[int]] -\n",
    "    Uma lista onde cada cluster é representado por uma lista aninhada contendo os targets (y)\n",
    "    correspondentes a tal cluster.\n",
    "  n_clusters : int -\n",
    "    O número de clusters.\n",
    "\n",
    "  Retorna\n",
    "  ----------\n",
    "  dict[int, int]\n",
    "    Um dicionário com o cluster como chave e o target correspondente a ele como valor\n",
    "  \"\"\"\n",
    "  mapping = {}\n",
    "  \n",
    "  for c in range(n_clusters):\n",
    "    counter = Counter(mapped_cluster_labels[c])  # contar a classe que mais aparece no cluster c\n",
    "    target = counter.most_common(1)[0][0]  # retorna a classe com maior frequência\n",
    "    mapping[c] = target  # mapear o valor do cluster c para o valor da classe correspondente\n",
    "  \n",
    "  return mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino do modelo e aplicação do mapeamento\n",
    "Além do modelo ser treinado, os clusters precisam ser mapeados para as suas classes correspondentes\n",
    "(targets correspondentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média do K-Means com 7 clusters: 80.13%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# O número de clusters é igual ao número de classes\n",
    "KMEANS_NUM_OF_CLUSTERS = len(set(y))\n",
    "\n",
    "kmeans_results = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "  kmeans_model = KMeans(n_clusters=KMEANS_NUM_OF_CLUSTERS, random_state=42)\n",
    "  kmeans_model = kmeans_model.fit(X_train[i])\n",
    "\n",
    "  mapped_cluster_labels = map_clusters_to_labels(kmeans_model, KMEANS_NUM_OF_CLUSTERS, y_train[i])\n",
    "  mapping = create_label_to_class_mapping(mapped_cluster_labels, KMEANS_NUM_OF_CLUSTERS)\n",
    "\n",
    "  # neste caso, não podemos usar o predict_and_get_accuracy pois precisamos mapear os resultados\n",
    "  # antes de obter a acurácia\n",
    "  current_result = kmeans_model.predict(X_test[i])\n",
    "  current_result = [mapping[i] for i in current_result]\n",
    "\n",
    "  kmeans_results.append(metrics.accuracy_score(y_test[i], current_result))\n",
    "\n",
    "print(f\"Acurácia média do K-Means com {KMEANS_NUM_OF_CLUSTERS} clusters: { \\\n",
    "  np.mean(kmeans_results)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
